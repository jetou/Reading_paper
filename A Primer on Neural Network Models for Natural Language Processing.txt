				A Primer on Neural Network Models
				for Natural Language Processing


简要
在过去的几年,神经网络是非常牛逼的机器学习算法,在许多的领域产生了非常先进的结果比如说图片识别语音处理.最近神经网络模型开始处理应用在处理自然语言符号,再次取得了非常好的结果.本教程调查神经网络模型从自然语言处理研究的角度出发,试图让自然语言的研究人员加快神经技术的速度.本教程介绍自然语言任务的输入编码,前馈网络，卷积网络，递归网络和递归网络，以及用于自动梯度计算的计算图抽象。

导读

在过去的十年,NLP的核心技是机器学习的方法用线性模型占主导地位,比如说support vector machines或logistic regression,来训练非常高维度但非常稀疏的特征向量.
最近，该领域在从稀疏输入的这种线性模型转换到密集输入的非线性神经网络模型方面取得了一些成功。虽然大多数神经网络技术很容易应用,有时也几乎取代旧的线性分类器,但在许多情况下,还是有很高的门槛.
这本入门书不是为了为了那些继续进步开发神经网络机器的综合资源(尽管它是一个很好的入口点).相反,它是针对对现有资源感兴趣的阅读者,有用的技术并以有用的创造性的方法用于其喜爱的NLP问题上.为了更加深入,更加全面的讨论神经网络背后的问题,高级的优化方法和其他高级的主题读者可以参考其他的资源.

范围

    这本书的注意力在用神经网络对自然语言处理的任务上,但是一些神经网络语言处理的子区域故意不在本书范围内.这些包括大量的语言建模和声学建模，使用神经网络进行机器翻译，以及多语言应用程序结合语言和其他信号，如图像和视频（如字幕生成）。对于高效运行时性能的缓存方法、大输出词汇表和注意力模型的有效训练方法也没有讨论。字符嵌入,只讨论需要使用他们作为其他模型的输入时的程度.其他无监督的方法，包括自动编码器和递归自动编码器，也不属于此范围。虽然在文中提到了神经网络在语言建模和机器翻译方面的一些应用，但它们的处理并不全面。

术语说明

    "特征"一次用于指代具体的语言输入,如单词后缀或词性标签.例如，在一阶词性标注器中，特征可能是“当前词，前一个词，下一个词，以前的词性”。 术语“输入矢量”用于指代被馈送到神经网络分类器的实际输入。 类似地，“输入向量条目”是指输入的特定值。 这与许多神经网络文献形成对比，其中“特征”一词在这两种用途之间被重载，主要用于指输入矢量条目。

数学符号

   用大写字母来代表矩阵(X,Y,Z),用小写字母来代表向量(b).当存在一系列相关的矩阵和向量（例如，每个矩阵对应于网络中的不同层）时，使用上标索引(W 1 , W 2 )对于我们希望指示矩阵或向量的功能的罕见情况，在需要取幂的项目周围添加一对括号：（W）2，（W 3）2。 除非另有说明，否则向量被假定为行向量。 我们使用[v 1; v 2]表示向量级联。
   使用右乘矩阵（xW + b）的行向量的选择有点不标准 - 许多神经网络文献使用左乘矩阵（Wx + b）的列向量。 我们相信读者在阅读文献时能够适应列向量符号。

神经网络架构

    神经网络是强大的学习模型。 我们将讨论两种可混合和匹配的神经网络架构 - 前馈网络和递归/递归网络,前馈网络包括具有完全连接层的网络，例如多层感知器，以及具有卷积层和汇聚层的网络。 所有网络都充当分类器，但每个网络都有不同的优势。
    完全连接的前馈神经网络（第4节）是非线性学习器，在大多数情况下，可以用作任何使用线性学习器的插入式替换器。 这包括二元和多类分类问题，以及更复杂的结构预测问题（第8节）。网络的非线性以及容易集成预先训练的词嵌入的能力通常会导致更高的分类精度。 一系列工作设法通过简单地用一个完全连接的前馈网络来替换解析器的线性模型来获得改进的句法分析结果。 前馈网络作为分类器替换的直接应用（通常与使用预先训练的词向量相结合）也为CCG超标记，对话状态跟踪，统计机器翻译的预订和语言建模提供了好处。Iyyer，Manjunatha，Boyd-Graber和DauméIII（2015）证明，多层前馈网络可以在情感分类和真实问题回答方面提供有竞争力的结果。
    具有卷积层和汇集层的网络（第9节）对分类任务非常有用，我们希望在这些分类任务中找到关于类成员的强大本地线索，但这些线索可能出现在输入的不同位置。 例如，在文档分类任务中，单个关键短语（或ngram）可以帮助确定文档主题（Johnson＆Zhang，2015）。
